{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pitch_data import load_data # This is the custom function I built to load the data from cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded!\n"
     ]
    }
   ],
   "source": [
    "pitches, metadata = load_data() # Function at work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More imports\n",
    "# Importing sklearn packages for simple dummy classifiers\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the column names from the sandbox notebook \n",
    "pitches_to_replace = pitches['pitch_type'].dropna().value_counts(normalize=True)\n",
    "pitches_to_replace = pitches_to_replace.where(pitches_to_replace <= .05).dropna().index.to_list()\n",
    "pitches['pitch_type'] = pitches['pitch_type'].replace(pitches_to_replace, \"other\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up dummy clf\n",
    "\n",
    "response_var = 'pitch_type' # y variable\n",
    "df = pitches.dropna(subset = [response_var]) # only completed pitch vars\n",
    "\n",
    "## Train test split but just train because dummy clf means no data leakage\n",
    "train_X = df.drop(response_var, axis = 1) # X\n",
    "train_y = df[response_var] # y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00     72641\n",
      "          CU       0.00      0.00      0.00     56379\n",
      "          FC       0.00      0.00      0.00     41702\n",
      "          FF       0.33      1.00      0.50    238541\n",
      "          FT       0.00      0.00      0.00     81056\n",
      "          SI       0.00      0.00      0.00     87740\n",
      "          SL       0.00      0.00      0.00    109756\n",
      "       other       0.00      0.00      0.00     28866\n",
      "\n",
      "    accuracy                           0.33    716681\n",
      "   macro avg       0.04      0.12      0.06    716681\n",
      "weighted avg       0.11      0.33      0.17    716681\n",
      "\n",
      "prior\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.00      0.00      0.00     72641\n",
      "          CU       0.00      0.00      0.00     56379\n",
      "          FC       0.00      0.00      0.00     41702\n",
      "          FF       0.33      1.00      0.50    238541\n",
      "          FT       0.00      0.00      0.00     81056\n",
      "          SI       0.00      0.00      0.00     87740\n",
      "          SL       0.00      0.00      0.00    109756\n",
      "       other       0.00      0.00      0.00     28866\n",
      "\n",
      "    accuracy                           0.33    716681\n",
      "   macro avg       0.04      0.12      0.06    716681\n",
      "weighted avg       0.11      0.33      0.17    716681\n",
      "\n",
      "stratified\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.10      0.10      0.10     72641\n",
      "          CU       0.08      0.08      0.08     56379\n",
      "          FC       0.06      0.06      0.06     41702\n",
      "          FF       0.33      0.33      0.33    238541\n",
      "          FT       0.11      0.11      0.11     81056\n",
      "          SI       0.12      0.12      0.12     87740\n",
      "          SL       0.15      0.15      0.15    109756\n",
      "       other       0.04      0.04      0.04     28866\n",
      "\n",
      "    accuracy                           0.18    716681\n",
      "   macro avg       0.13      0.13      0.13    716681\n",
      "weighted avg       0.18      0.18      0.18    716681\n",
      "\n",
      "uniform\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.10      0.12      0.11     72641\n",
      "          CU       0.08      0.12      0.10     56379\n",
      "          FC       0.06      0.12      0.08     41702\n",
      "          FF       0.33      0.12      0.18    238541\n",
      "          FT       0.11      0.12      0.12     81056\n",
      "          SI       0.12      0.13      0.12     87740\n",
      "          SL       0.15      0.12      0.14    109756\n",
      "       other       0.04      0.13      0.06     28866\n",
      "\n",
      "    accuracy                           0.12    716681\n",
      "   macro avg       0.12      0.12      0.11    716681\n",
      "weighted avg       0.18      0.12      0.14    716681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building dummy model for each fit\n",
    "\n",
    "strats = [\"most_frequent\", \"prior\", \"stratified\", \"uniform\"] ## Iterating over each dummy model to see which is best performing\n",
    "dummy_results = {} # Results in dict\n",
    "for strat in strats: \n",
    "    d_clf = DummyClassifier(strategy=strat) # instantiate dummy clf with strat from loop\n",
    "    d_clf.fit(train_X,train_y) # fit model\n",
    "    print(strat) # print results and model strategy\n",
    "    print(classification_report(train_y, d_clf.predict(train_X),zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My goal is to build a regressor with an accuracy > .33 with weighted f1 > .18. \n",
    "# To be honest, this shouldn't be too hard, so I'll do a simple classification task in the best interest of time and simplicity.\n",
    "# Basically, I'm trying to do better than randomly guessing using the four dummy strategies above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
